{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OrMaicTTFgpT"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ’½ Install RVC & Connect to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "from multiprocessing import cpu_count\n",
        "cpu_cores = cpu_count()\n",
        "LOGS_PATH = \"/content/Applio/logs\"\n",
        "\n",
        "%cd /content\n",
        "!git config --global advice.detachedHead false\n",
        "!git clone https://github.com/IAHispano/Applio --branch 3.5.1 --single-branch\n",
        "%cd /content/Applio\n",
        "\n",
        "!apt update -y\n",
        "!apt install -y python3.11 python3.11-distutils python3.11-dev portaudio19-dev\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2\n",
        "!update-alternatives --set python3 /usr/bin/python3.11\n",
        "from sys import path\n",
        "path.append('/usr/local/lib/python3.11/dist-packages')\n",
        "\n",
        "print(\"Installing requirements...\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!uv pip install -q -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu128 --index-strategy unsafe-best-match\n",
        "!uv pip install -q jupyter-ui-poll\n",
        "!uv pip install -q \"audio-separator[gpu]==0.17.5\"\n",
        "!uv pip install -q demucs yt_dlp pydub\n",
        "!python core.py \"prerequisites\" --models \"True\" --pretraineds_hifigan \"True\"\n",
        "print(\"Finished installing requirements!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸµâœ‚ï¸ğŸ¤ Separation (BS-Roformer and Mel Band Roformer)\n",
        "#@markdown #### Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ ØªØ±Ø§Ú© Ø±Ø§ Ø¨ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ø±Ø¯ÛŒÙ†ØŒ ÙÛŒÙ„Ø¯ Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø´Ú©Ù„ Ø¨Ø§Ù‚ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯\n",
        "import os\n",
        "import glob\n",
        "import yt_dlp\n",
        "\n",
        "def downloader(url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': '/content/temp/%(title)s.%(ext)s',\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "def checker(url):\n",
        "    return \"http\" in url\n",
        "\n",
        "def uvr_cli(audio_input, output_folder, extensions, output_format, model, overlap, segment_size):\n",
        "    found_files = []\n",
        "    dictmodel = {\n",
        "        'BS-Roformer-Viperx-1297.ckpt': 'model_bs_roformer_ep_317_sdr_12.9755.ckpt',\n",
        "        'BS-Roformer-Viperx-1296.ckpt': 'model_bs_roformer_ep_368_sdr_12.9628.ckpt',\n",
        "        'BS-Roformer-Viperx-1053.ckpt': 'model_bs_roformer_ep_937_sdr_10.5309.ckpt',\n",
        "        'Mel-Roformer-Viperx-1143.ckpt': 'model_mel_band_roformer_ep_3005_sdr_11.4360.ckpt'\n",
        "    }\n",
        "    roformer_model = dictmodel[model]\n",
        "\n",
        "    if checker(audio_input):\n",
        "        os.makedirs('/content/temp', exist_ok=True)\n",
        "        downloader(audio_input)\n",
        "        audio_input = \"/content/temp\"\n",
        "\n",
        "    for audio_files in os.listdir(audio_input):\n",
        "        if audio_files.endswith(extensions):\n",
        "            found_files.append(audio_files)\n",
        "\n",
        "    total_files = len(found_files)\n",
        "    if total_files == 0:\n",
        "        print(\"No valid audio files found.\")\n",
        "    else:\n",
        "        print(f\"{total_files} audio files found\")\n",
        "        found_files.sort()\n",
        "        for audio_files in found_files:\n",
        "            file_path = os.path.join(audio_input, audio_files)\n",
        "            prompt = f'audio-separator \"{file_path}\" --model_filename {roformer_model} --output_dir={output_folder} --output_format={output_format} --normalization=0.9 --mdxc_overlap={overlap} --mdxc_segment_size={segment_size}'\n",
        "            !$prompt\n",
        "\n",
        "    if audio_input == \"/content/temp\":\n",
        "        temp_files = glob.glob(\"/content/temp/*\")\n",
        "        for file in temp_files:\n",
        "            os.remove(file)\n",
        "\n",
        "audio_input = \"/content\" #@param {type:\"string\"}\n",
        "output_folder = \"/content/drive/MyDrive/Vocales\" #@param {type:\"string\"}\n",
        "model = \"BS-Roformer-Viperx-1297.ckpt\" #@param [\"BS-Roformer-Viperx-1297.ckpt\", \"BS-Roformer-Viperx-1296.ckpt\", \"BS-Roformer-Viperx-1053.ckpt\", \"Mel-Roformer-Viperx-1143.ckpt\"]\n",
        "output_format = \"wav\" #@param [\"wav\", \"flac\", \"mp3\"]\n",
        "overlap = 4 #@param {type:\"slider\", min:2, max:4, step:1}\n",
        "segment_size = 256 #@param {type:\"slider\", min:32, max:4000, step:32}\n",
        "extensions = (\".mp3\", \".wav\", \".flac\")\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "uvr_cli(audio_input, output_folder, extensions, output_format, model, overlap, segment_size)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FcyAyD2LFr8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Model (ZIP, TAR.GZ, or Drive Link)\n",
        "Model_Name = \"\" #@param {type:\"string\"}\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import tarfile  # Import tarfile for signature check\n",
        "\n",
        "if not Model_Name:\n",
        "    print(\"âŒ Error: Please enter the Model Name.\")\n",
        "else:\n",
        "    # Create model directory in target path\n",
        "    target_dir = f\"/content/Applio/logs/{Model_Name}\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    print(f\"Target directory created/exists: {target_dir}\")\n",
        "\n",
        "    # --- Download ---\n",
        "    downloaded_file_path = \"/content/downloaded_model\"\n",
        "    try:\n",
        "        if 'drive.google.com' in MODEL_LINK:\n",
        "            print(\"Downloading from Google Drive...\")\n",
        "            gdown.download(MODEL_LINK, downloaded_file_path, quiet=False, fuzzy=True)\n",
        "        elif MODEL_LINK.endswith(('.zip', '.tar.gz')):\n",
        "            print(f\"Downloading from direct link ({MODEL_LINK})...\")\n",
        "            os.system(f'wget -O {downloaded_file_path} \"{MODEL_LINK}\"')\n",
        "        else:\n",
        "            print(\"âŒ Error: Unsupported link type. Please provide a Google Drive link or a direct link to a .zip or .tar.gz file.\")\n",
        "            downloaded_file_path = None  # Indicate download failure\n",
        "\n",
        "        if downloaded_file_path and os.path.exists(downloaded_file_path):\n",
        "            print(\"âœ… Download successful.\")\n",
        "        elif downloaded_file_path:\n",
        "            print(\"âŒ Error: Download failed or file not found after download attempt.\")\n",
        "            downloaded_file_path = None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error during download: {e}\")\n",
        "        downloaded_file_path = None\n",
        "\n",
        "    # --- Extraction ---\n",
        "    if downloaded_file_path:\n",
        "        file_type = None\n",
        "        try:\n",
        "            # Try identifying as tar.gz first\n",
        "            with tarfile.open(downloaded_file_path, 'r:*') as tar:  # auto-detect compression\n",
        "                file_type = 'tar'\n",
        "                print(\"Detected file type: tar archive\")\n",
        "                temp_extract_dir = \"/content/temp_extract\"\n",
        "                os.makedirs(temp_extract_dir, exist_ok=True)\n",
        "                print(f\"Extracting {downloaded_file_path} to {temp_extract_dir}...\")\n",
        "                tar.extractall(path=temp_extract_dir)\n",
        "\n",
        "        except tarfile.ReadError:\n",
        "            # If not a tarfile, try as zip\n",
        "            try:\n",
        "                import zipfile\n",
        "                if zipfile.is_zipfile(downloaded_file_path):\n",
        "                    file_type = 'zip'\n",
        "                    print(\"Detected file type: zip archive\")\n",
        "                    print(f\"Extracting {downloaded_file_path} to {target_dir}...\")\n",
        "                    with zipfile.ZipFile(downloaded_file_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(target_dir)\n",
        "                else:\n",
        "                    print(\"âŒ Error: File is not a valid zip or tar archive.\")\n",
        "            except Exception as zip_e:\n",
        "                print(f\"âŒ Error processing as zip file: {zip_e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error during extraction detection/setup: {e}\")\n",
        "\n",
        "        # --- Copying/Moving files specifically for TAR archives ---\n",
        "        if file_type == 'tar':\n",
        "            files_copied = False\n",
        "            # Search and copy required files using os.walk\n",
        "            for root, dirs, files in os.walk(temp_extract_dir):\n",
        "                for file in files:\n",
        "                    if file.endswith('.pth'):\n",
        "                        source_path = os.path.join(root, file)\n",
        "                        dest_path = os.path.join(target_dir, file)\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                        print(f\"Copied PTH: {file} to {target_dir}\")\n",
        "                        files_copied = True\n",
        "\n",
        "                    if file.endswith('.index'):\n",
        "                        source_path = os.path.join(root, file)\n",
        "                        dest_path = os.path.join(target_dir, file)\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                        print(f\"Copied INDEX: {file} to {target_dir}\")\n",
        "                        files_copied = True\n",
        "\n",
        "            if not files_copied:\n",
        "                print(\"âš ï¸ Warning: No .pth or .index files found during deep search in extracted tar.\")\n",
        "\n",
        "            # Clean up temp extraction dir for tar\n",
        "            if os.path.exists(temp_extract_dir):\n",
        "                shutil.rmtree(temp_extract_dir)\n",
        "                print(f\"Removed temporary extraction directory: {temp_extract_dir}\")\n",
        "\n",
        "        # --- Cleanup Extraneous PTH Files (for BOTH zip and tar) ---\n",
        "        print(\"\\nğŸ§¹ Starting cleanup of extraneous PTH files...\")\n",
        "        expected_model_pth_filename = f\"{Model_Name}.pth\"\n",
        "        expected_model_pth_full_path = os.path.join(target_dir, expected_model_pth_filename)\n",
        "\n",
        "        # List all .pth files currently in the target directory\n",
        "        pth_files_in_target = glob.glob(os.path.join(target_dir, \"*.pth\"))\n",
        "        found_expected_pth = False\n",
        "\n",
        "        if not pth_files_in_target:\n",
        "            print(f\"âŒ Warning: No .pth files found in the final target directory {target_dir}.\")\n",
        "        else:\n",
        "            print(f\"Found PTH files: {[os.path.basename(f) for f in pth_files_in_target]}\")\n",
        "            # Check if the main expected file exists\n",
        "            if expected_model_pth_full_path in pth_files_in_target:\n",
        "                found_expected_pth = True\n",
        "                print(f\"âœ… Expected model file '{expected_model_pth_filename}' found.\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ Warning: Expected model file '{expected_model_pth_filename}' NOT found.\")\n",
        "\n",
        "            # Remove files starting with G_ or D_ OR any pth file if the expected one exists but this one isn't it\n",
        "            for pth_file_path in pth_files_in_target:\n",
        "                filename = os.path.basename(pth_file_path)\n",
        "                if filename.startswith(\"G_\") or filename.startswith(\"D_\"):\n",
        "                    try:\n",
        "                        os.remove(pth_file_path)\n",
        "                        print(f\"ğŸ§¹ Removed checkpoint file: {filename}\")\n",
        "                    except OSError as e:\n",
        "                        print(f\"âŒ Error removing file {filename}: {e}\")\n",
        "                elif found_expected_pth and pth_file_path != expected_model_pth_full_path:\n",
        "                    try:\n",
        "                        os.remove(pth_file_path)\n",
        "                        print(f\"ğŸ§¹ Removed other PTH file (since expected exists): {filename}\")\n",
        "                    except OSError as e:\n",
        "                        print(f\"âŒ Error removing file {filename}: {e}\")\n",
        "\n",
        "        # ğŸ” Ø§ÛŒÙ†Ø¬Ø§ Ù…Ù†Ø·Ù‚ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù†Ø§Ù… ØµØ­ÛŒØ­ Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        final_pth_files = glob.glob(os.path.join(target_dir, \"*.pth\"))\n",
        "        if final_pth_files:\n",
        "            # Ø§Ú¯Ø± Ù†Ø§Ù… ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø¹Ø« Ù†Ø´Ø¯Ù‡ ÙØ§ÛŒÙ„ {Model_Name}.pth Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆØ¯ØŒ\n",
        "            # ÙˆÙ„ÛŒ ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ pth Ø¯ÛŒÚ¯Ø± Ù‡Ø³ØªØŒ ÛŒÚ©ÛŒ Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡\n",
        "            if expected_model_pth_full_path not in final_pth_files:\n",
        "                # Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø­Ø§Ù„Øª: Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† pth Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù†Ø§Ù… ØµØ­ÛŒØ­ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\n",
        "                suggested_full = sorted(final_pth_files)[-1]\n",
        "                suggested_base = os.path.basename(suggested_full)\n",
        "                suggested_name = os.path.splitext(suggested_base)[0]\n",
        "\n",
        "                print(\"\\nâš ï¸ ØªÙˆØ¬Ù‡: Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ù†Ø§Ù…ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯ÛŒØ¯ Ø¨Ø§ Ù†Ø§Ù… ÙˆØ§Ù‚Ø¹ÛŒ ÙØ§ÛŒÙ„ pth ÛŒÚ©ÛŒ Ù†ÛŒØ³Øª.\")\n",
        "                print(f\"Ù†Ø§Ù… ØµØ­ÛŒØ­ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§ÛŒÙ† Ø§Ø³Øª:\")\n",
        "                print(f\"ğŸ‘‰  {suggested_name}\")\n",
        "                print(\"Ù„Ø·ÙØ§Ù‹ Ù‡Ù…ÛŒÙ† Ù†Ø§Ù… Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯ Ø¯Ø± ÙÛŒÙ„Ø¯ Ù†Ø§Ù… Ù…Ø¯Ù„ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ø³Ù„ÙˆÙ„ Ø§ÛŒÙ†ÙØ±ÙÙ†Ø³ Ø¯Ø±Ø³Øª Ú©Ø§Ø± Ú©Ù†Ø¯.\")\n",
        "\n",
        "        # Final listing to confirm\n",
        "        print(f\"\\nâœ… Extraction and cleanup complete for model '{Model_Name}'. Final contents:\")\n",
        "        os.system(f'ls -la \"{target_dir}\"')\n",
        "\n",
        "        # Clean up the downloaded archive file\n",
        "        os.remove(downloaded_file_path)\n",
        "        print(f\"Removed downloaded archive: {downloaded_file_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Skipping extraction due to download failure.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bBoxm_yGPvik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Inference (Auto Load Vocals from Drive)\n",
        "%cd /content/Applio\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "input_directory = \"/content/drive/MyDrive/Vocales\"\n",
        "\n",
        "audio_file = None\n",
        "for file in os.listdir(input_directory):\n",
        "    if \"Vocals\" in file and file.lower().endswith(('.mp3', '.wav', '.flac', '.ogg', '.m4a')):\n",
        "        audio_file = os.path.join(input_directory, file)\n",
        "        break\n",
        "\n",
        "if audio_file is None:\n",
        "    print(\"No Vocals file found!\")\n",
        "    raise SystemExit\n",
        "\n",
        "new_audio_path = \"/content/input.wav\"\n",
        "shutil.copy(audio_file, new_audio_path)\n",
        "print(f\"Loaded: {audio_file}\")\n",
        "\n",
        "model_name = \"\" #@param {type:\"string\"}\n",
        "model_path = Path(f\"{LOGS_PATH}/{model_name}\")\n",
        "if not (model_path.exists() and model_path.is_dir()):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_path.resolve()}\")\n",
        "\n",
        "!ls -t \"{model_path}\"/\"{model_name}\"_*e_*s.pth \"{model_path}\"/\"{model_name}\".pth 2> /dev/null | head -n 1 > /tmp/pth.txt\n",
        "pth_file = open(\"/tmp/pth.txt\", \"r\").read().strip()\n",
        "if pth_file == \"\":\n",
        "    raise FileNotFoundError(f\"No model weight found\")\n",
        "\n",
        "!ls -t \"{model_path}\"/*.index | head -n 1 > /tmp/index.txt\n",
        "index_file = open(\"/tmp/index.txt\", \"r\").read().strip()\n",
        "\n",
        "input_path = new_audio_path\n",
        "output_path = \"/content/output.wav\"\n",
        "export_format = \"WAV\" #@param ['WAV', 'MP3', 'FLAC', 'OGG', 'M4A']\n",
        "f0_method = \"rmvpe\" #@param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\", \"hybrid[rmvpe+fcpe]\"]\n",
        "f0_up_key = 0 #@param {type:\"slider\", min:-24, max:24, step:1}\n",
        "rms_mix_rate = 0.8 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "protect = 0.5 #@param {type:\"slider\", min:0.0, max:0.5, step:0.1}\n",
        "index_rate = 0.7 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "clean_strength = 0.7 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "split_audio = False #@param{type:\"boolean\"}\n",
        "clean_audio = False #@param{type:\"boolean\"}\n",
        "f0_autotune = False #@param{type:\"boolean\"}\n",
        "formant_shift = False #@param{type:\"boolean\"}\n",
        "formant_qfrency = 1.0 #@param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "formant_timbre = 1.0 #@param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "embedder_model = \"contentvec\" #@param [\"contentvec\", \"chinese-hubert-base\", \"japanese-hubert-base\", \"korean-hubert-base\", \"custom\"]\n",
        "embedder_model_custom = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!rm -f \"{output_path}\"\n",
        "!python core.py infer --pitch \"{f0_up_key}\" --volume_envelope \"{rms_mix_rate}\" --index_rate \"{index_rate}\" --protect \"{protect}\" --f0_autotune \"{f0_autotune}\" --f0_method \"{f0_method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"{export_format}\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\" --formant_shifting \"{formant_shift}\" --formant_qfrency \"{formant_qfrency}\" --formant_timbre \"{formant_timbre}\"\n",
        "\n",
        "if Path(output_path).exists():\n",
        "    from IPython.display import Audio, display\n",
        "    output_path = output_path.replace(\".wav\", f\".{export_format.lower()}\")\n",
        "    display(Audio(output_path, autoplay=True))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dAv2dn_bGAAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mix with Instrumental\n",
        "#@markdown ####  ğŸ”€ ØªØ±Ú©ÛŒØ¨ ØµØ¯Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆØ²ÛŒÚ© Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "music_directory = \"/content/drive/MyDrive/Vocales\"\n",
        "\n",
        "music_file = None\n",
        "for file in os.listdir(music_directory):\n",
        "    if \"Instrumental\" in file and file.lower().endswith(('.mp3', '.wav', '.flac', '.ogg', '.m4a')):\n",
        "        music_file = os.path.join(music_directory, file)\n",
        "        break\n",
        "\n",
        "if music_file is None:\n",
        "    print(\"No Instrumental file found!\")\n",
        "    raise SystemExit\n",
        "\n",
        "processed_audio_path = \"/content/output.wav\"\n",
        "if not os.path.exists(processed_audio_path):\n",
        "    print(\"Processed audio not found!\")\n",
        "    raise SystemExit\n",
        "\n",
        "voice = AudioSegment.from_file(processed_audio_path)\n",
        "music = AudioSegment.from_file(music_file)\n",
        "\n",
        "if len(music) > len(voice):\n",
        "    music = music[:len(voice)]\n",
        "else:\n",
        "    voice = voice[:len(music)]\n",
        "\n",
        "mixed_audio = voice.overlay(music, position=0, gain_during_overlay=-5)\n",
        "final_output_path = \"/content/mixed_output.wav\"\n",
        "mixed_audio.export(final_output_path, format=\"wav\")\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(final_output_path, autoplay=True))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9i2HCNXRGGTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Final Output\n",
        "#@markdown ####ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù…ÛŒÚ©Ø³â€Œ Ø´Ø¯Ù‡\n",
        "from google.colab import files\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "output_files = glob.glob(\"/content/output.*\") + glob.glob(\"/content/mixed_output.*\")\n",
        "if not output_files:\n",
        "    print(\"No output files found\")\n",
        "else:\n",
        "    latest_file = max(output_files, key=os.path.getmtime)\n",
        "    print(f\"Downloading: {os.path.basename(latest_file)}\")\n",
        "    display(Audio(latest_file, autoplay=False))\n",
        "    files.download(latest_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a9UUUoNIGLZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}