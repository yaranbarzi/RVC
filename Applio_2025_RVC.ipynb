{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <a href=\"https://github.com/IAHispano\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Thanks%20to-IAHispano-green?style=for-the-badge&logo=github\" alt=\"Thanks to\"/>\n",
        "  </a>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "kwz8wJ6d_SRh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMCTSD6m8qV"
      },
      "source": [
        "### **Install Applio**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yFhAeKGOp9aa"
      },
      "outputs": [],
      "source": [
        "# @title Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7GysECSxBya4"
      },
      "outputs": [],
      "source": [
        "# @title Clone\n",
        "import os\n",
        "!git clone https://github.com/IAHispano/Applio --branch 3.5.1 --single-branch\n",
        "%cd /content/Applio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CAXW55BQm0PP"
      },
      "outputs": [],
      "source": [
        "# @title Install\n",
        "\n",
        "!apt update -y\n",
        "!apt install -y python3.11 python3.11-distutils python3.11-dev portaudio19-dev\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2\n",
        "!update-alternatives --set python3 /usr/bin/python3.11\n",
        "from sys import path\n",
        "path.append('/usr/local/lib/python3.11/dist-packages')\n",
        "\n",
        "print(\"Installing requirements...\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!uv pip install -q -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu128 --index-strategy unsafe-best-match\n",
        "!uv pip install -q jupyter-ui-poll\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Installing requirements...\")\n",
        "# Ù†ØµØ¨ Ù¾ÛŒØ´Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„\n",
        "!python core.py \"prerequisites\" --models \"True\" --exe \"True\" --pretraineds_hifigan \"True\"\n",
        "clear_output()\n",
        "print(\"Finished installing requirements!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QkabnLlF2KB"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oBzqm4JkGGa0"
      },
      "outputs": [],
      "source": [
        "# @title Preprocess Dataset\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "model_name = \"\"  # @param {type:\"string\"}\n",
        "dataset_path = \"/content/drive/MyDrive/\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´:**\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "# @markdown > Ø·ÙˆÙ„ Ù‡Ø± Ù‚Ø·Ø¹Ù‡ ØµÙˆØªÛŒ (Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡) Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯.\n",
        "chunk_len = 3 # @param {type:\"slider\", min:0.5, max:5.0, step:0.5}\n",
        "\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "cpu_cores = 2\n",
        "cut_preprocess = \"Automatic\"\n",
        "overlap_len = 0.3\n",
        "process_effects = False\n",
        "noise_reduction = False\n",
        "noise_reduction_strength = 0.7\n",
        "normalization_mode = \"none\" # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù†Ø³Ø®Ù‡ 3.5.1\n",
        "\n",
        "print(\"Starting preprocessing...\")\n",
        "!python core.py preprocess --model_name \"{model_name}\" --dataset_path \"{dataset_path}\" --sample_rate \"{sr}\" --cpu_cores \"{cpu_cores}\" --cut_preprocess \"{cut_preprocess}\" --process_effects \"{process_effects}\" --noise_reduction \"{noise_reduction}\" --noise_reduction_strength \"{noise_reduction_strength}\" --chunk_len \"{chunk_len}\" --overlap_len \"{overlap_len}\" --normalization_mode \"{normalization_mode}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zWMiMYfRJTJv"
      },
      "outputs": [],
      "source": [
        "# @title Extract Features\n",
        "# @markdown ### Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬\n",
        "f0_method = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\"] {allow-input: false}\n",
        "embedder_model = \"contentvec\" # @param [\"contentvec\", \"chinese-hubert-base\", \"japanese-hubert-base\", \"korean-hubert-base\", \"custom\"] {allow-input: false}\n",
        "embedder_model_custom = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# Ù¾Ø§Ø±Ø§Ù…ØªØ± hop_length Ø¯Ø± Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø­Ø°Ù Ø´Ø¯Ù‡ Ø§Ø³Øª\n",
        "cpu_cores = 2\n",
        "include_mutes = 2\n",
        "\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "\n",
        "print(\"Starting feature extraction...\")\n",
        "!python core.py extract --model_name \"{model_name}\" --f0_method \"{f0_method}\" --sample_rate \"{sr}\" --cpu_cores \"{cpu_cores}\" --gpu \"0\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\"  --include_mutes \"{include_mutes}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ”„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² Ø¯Ø±Ø§ÛŒÙˆ ( ÙÙ‚Ø· Ø¬Ù‡Øª Ø§Ø±ØªÙ‚Ø§ÛŒ Ù…Ø¯Ù„Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´ÙˆØ¯)\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Ù†Ø§Ù… Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:\n",
        "model_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not model_name.strip():\n",
        "    print(\"âŒ Ù„Ø·ÙØ§ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø±Ø§ Ø¯Ø± ÙÛŒÙ„Ø¯ Ø¨Ø§Ù„Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\")\n",
        "else:\n",
        "    # Ù…Ø³ÛŒØ± Ø¨Ú©Ø§Ù¾ Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ (Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ø³Ù„ÙˆÙ„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ù…Ø§)\n",
        "    src_folder = f'/content/drive/MyDrive/RVC_backup/{model_name}'\n",
        "    # Ù…Ø³ÛŒØ± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Applio Ø¯Ø± Ù…Ø­ÛŒØ· Ú©Ø§Ø±ÛŒ Colab\n",
        "    dst_folder = f'/content/Applio/logs/{model_name}'\n",
        "\n",
        "    print(f\"Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ '{model_name}' Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ...\")\n",
        "\n",
        "    if os.path.exists(src_folder):\n",
        "        print(f\"âœ… Ù…Ø¯Ù„ Ù¾ÛŒØ¯Ø§ Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ø²:\\n  > {src_folder}\\nØ¨Ù‡:\\n  > {dst_folder}\")\n",
        "\n",
        "        # Ø§Ú¯Ø± Ù¾ÙˆØ´Ù‡ Ù…Ù‚ØµØ¯ Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ø¢Ù† Ø±Ø§ Ù¾Ø§Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´ÙˆÙ†Ø¯\n",
        "        if os.path.exists(dst_folder):\n",
        "            shutil.rmtree(dst_folder)\n",
        "\n",
        "        # Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† Ú©Ù„ Ù¾ÙˆØ´Ù‡ Ù…Ø¯Ù„\n",
        "        try:\n",
        "            shutil.copytree(src_folder, dst_folder)\n",
        "            print(f\"\\nâœ…âœ…âœ… Ù…Ø¯Ù„ '{model_name}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ù…Ø­ÛŒØ· Ú©Ø§Ø±ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.\")\n",
        "            print(\"Ø§Ú©Ù†ÙˆÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ Ø³Ù„ÙˆÙ„ 'Start Training' Ø¨Ø±ÙˆÛŒØ¯ Ùˆ Ø§Ø¯Ø§Ù…Ù‡ ØªÙ…Ø±ÛŒÙ† Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"âŒ Ø®Ø·Ø§: Ù¾ÙˆØ´Ù‡ Ù…Ø¯Ù„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯:\\n  > {src_folder}\")\n",
        "        print(\"Ù„Ø·ÙØ§ Ø§Ø² Ø¯Ø±Ø³Øª Ø¨ÙˆØ¯Ù† Ù†Ø§Ù… Ù…Ø¯Ù„ Ùˆ ÙˆØ¬ÙˆØ¯ Ø¨Ú©Ø§Ù¾ Ø¢Ù† Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vBOTxYaopYnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TI6LLdIzKAIa"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title âš™ï¸ Start Training (Customized & Smart v2)\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "# --- Ø¨Ø®Ø´ ÙØ±Ù…â€ŒÙ‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ø±Ø¨Ø± ---\n",
        "\n",
        "# @markdown ### ğŸ’¾ Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ù†Ù…Ø§ÛŒØ´Ú¯Ø±\n",
        "auto_backups = False  # @param{type:\"boolean\"}\n",
        "tensorboard = True  # @param{type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø¢Ù…ÙˆØ²Ø´\n",
        "total_epoch = 25  # @param {type:\"integer\"}\n",
        "batch_size = 8  # @param {type:\"slider\", min:1, max:25, step:0}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ğŸ“¦ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ\n",
        "save_every_epoch = 10  # @param {type:\"slider\", min:1, max:100, step:0}\n",
        "save_only_latest = True  # @param{type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ğŸ“ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡\n",
        "overtraining_detector = True  # @param{type:\"boolean\"}\n",
        "overtraining_threshold = 50  # @param {type:\"slider\", min:1, max:100, step:0}\n",
        "custom_pretrained = False  # @param{type:\"boolean\"}\n",
        "g_pretrained_path = \"\"  # @param {type:\"string\"}\n",
        "d_pretrained_path = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### ğŸ› ï¸ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ (sample rate)\n",
        "\n",
        "manual_sample_rate = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ---\n",
        "cooldown = 15\n",
        "pretrained = True\n",
        "cleanup = False\n",
        "cache_data_in_gpu = False\n",
        "save_every_weights = False\n",
        "vocoder = \"HiFi-GAN\"\n",
        "checkpointing = False\n",
        "gpu = 0\n",
        "\n",
        "# ------------------- NEW: Smart Sample Rate Detection v2 -------------------\n",
        "print(\"Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø­Ø§Ù„Øª ØªÙ…Ø±ÛŒÙ†...\")\n",
        "sr = 40000  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "\n",
        "if manual_sample_rate.strip().isdigit():\n",
        "    sr = int(manual_sample_rate)\n",
        "    print(f\"âœ… Ø³Ù…Ù¾Ù„ Ø±ÛŒØª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ø±ÙˆÛŒ {sr} Hz ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯.\")\n",
        "elif custom_pretrained and g_pretrained_path.strip():\n",
        "    print(\"Ø­Ø§Ù„Øª Â«Ø§Ø¯Ø§Ù…Ù‡ ØªÙ…Ø±ÛŒÙ†Â» Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø³Ù…Ù¾Ù„ Ø±ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¯Ù„...\")\n",
        "    config_path = os.path.join(os.path.dirname(g_pretrained_path), \"config.json\")\n",
        "\n",
        "    if os.path.exists(config_path):\n",
        "        try:\n",
        "            with open(config_path, \"r\", encoding='utf-8') as f:\n",
        "                config = json.load(f)\n",
        "                if \"sample_rate\" in config:\n",
        "                    sr = int(config[\"sample_rate\"])\n",
        "                    print(f\"âœ… Ø³Ù…Ù¾Ù„ Ø±ÛŒØª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯: {sr} Hz\")\n",
        "                else:\n",
        "                    print(f\"âš ï¸ Ú©Ù„ÛŒØ¯ 'sample_rate' Ø¯Ø± ÙØ§ÛŒÙ„ config.json Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø² ÙÛŒÙ„Ø¯ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ config.json: {e}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² ÙÛŒÙ„Ø¯ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ ÙØ§ÛŒÙ„ config.json Ø¯Ø± Ù…Ø³ÛŒØ± {config_path} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø² ÙÛŒÙ„Ø¯ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\")\n",
        "\n",
        "else:\n",
        "    print(\"Ø­Ø§Ù„Øª Â«ØªÙ…Ø±ÛŒÙ† Ø¬Ø¯ÛŒØ¯Â» Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø³Ù…Ù¾Ù„ Ø±ÛŒØª Ø§Ø² Ø³Ù„ÙˆÙ„ Preprocess...\")\n",
        "    try:\n",
        "        sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "        print(f\"âœ… Ø³Ù…Ù¾Ù„ Ø±ÛŒØª Ø§Ø² Ø³Ù„ÙˆÙ„ Preprocess ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {sr} Hz\")\n",
        "    except NameError:\n",
        "        print(f\"âš ï¸ Ù…ØªØºÛŒØ± sample_rate ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ {sr} Hz Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\")\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def start_train():\n",
        "    if tensorboard:\n",
        "        %load_ext tensorboard\n",
        "        %tensorboard --logdir /content/Applio/logs/\n",
        "\n",
        "    !python core.py train --model_name \"{model_name}\" --save_every_epoch \"{save_every_epoch}\" --save_only_latest \"{save_only_latest}\" --save_every_weights \"{save_every_weights}\" --total_epoch \"{total_epoch}\" --sample_rate \"{sr}\" --batch_size \"{batch_size}\" --gpu \"{gpu}\" --pretrained \"{pretrained}\" --custom_pretrained \"{custom_pretrained}\" --g_pretrained_path \"{g_pretrained_path}\" --d_pretrained_path \"{d_pretrained_path}\" --overtraining_detector \"{overtraining_detector}\" --overtraining_threshold \"{overtraining_threshold}\" --cleanup \"{cleanup}\" --cache_data_in_gpu \"{cache_data_in_gpu}\" --vocoder \"{vocoder}\" --checkpointing \"{checkpointing}\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"âœ… Ø¢Ù…ÙˆØ²Ø´ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø§Ú©Ù†ÙˆÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø³Ù„ÙˆÙ„ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯.\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    if overtraining_detector:\n",
        "        print(\"ğŸ“œ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø§ Ø´Ù†Ø§Ø³Ø§Ú¯Ø± Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´ ÙØ¹Ø§Ù„):\")\n",
        "        print(\"- Ø¢Ù…ÙˆØ²Ø´ ÛŒØ§ Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ø§ÛŒÙ¾Ø§Ú© Ú©Ø§Ù…Ù„ (total_epoch) Ø±Ø³ÛŒØ¯Ù‡ ÛŒØ§ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´ Ø²ÙˆØ¯ØªØ± Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "    else:\n",
        "        print(\"ğŸ“œ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø§ Ø´Ù†Ø§Ø³Ø§Ú¯Ø± Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´ ØºÛŒØ±ÙØ¹Ø§Ù„):\")\n",
        "        print(\"- Ø¢Ù…ÙˆØ²Ø´ ØªØ§ Ø¢Ø®Ø±ÛŒÙ† Ø§ÛŒÙ¾Ø§Ú© Ù…Ø´Ø®Øµâ€ŒØ´Ø¯Ù‡ (total_epoch) Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§ÙØª.\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "\n",
        "server_thread = threading.Thread(target=start_train)\n",
        "server_thread.start()\n",
        "\n",
        "if auto_backups:\n",
        "    print(\"AutoBackup Enabled. Starting backup loop...\")\n",
        "    while server_thread.is_alive():\n",
        "        time.sleep(cooldown)\n",
        "else:\n",
        "    print(\"AutoBackup Disabled. The training will run without backups.\")\n",
        "    while server_thread.is_alive():\n",
        "        time.sleep(10)\n",
        "\n",
        "print(\"ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§ØµÙ„ÛŒ Ø³Ù„ÙˆÙ„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save\n",
        "model_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "src_folder = f'/content/Applio/logs/{model_name}'\n",
        "dst_folder = f'/content/drive/MyDrive/RVC_backup/{model_name}'\n",
        "\n",
        "os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(src_folder):\n",
        "    relative_path = os.path.relpath(root, src_folder)\n",
        "    dst_path = os.path.join(dst_folder, relative_path)\n",
        "    os.makedirs(dst_path, exist_ok=True)\n",
        "\n",
        "    for file in files:\n",
        "        src_file = os.path.join(root, file)\n",
        "        dst_file = os.path.join(dst_path, file)\n",
        "        try:\n",
        "            shutil.copy2(src_file, dst_file)\n",
        "            print(f'Ú©Ù¾ÛŒ Ø´Ø¯: {src_file} â†’ {dst_file}')\n",
        "        except Exception as e:\n",
        "            print(f'Ø®Ø·Ø§ Ø¯Ø± Ú©Ù¾ÛŒ \"{src_file}\": {e}')\n",
        "\n",
        "print(\"âœ… Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯Ù†Ø¯.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-SS6sFjUOg8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Ø°Ø®ÛŒØ±Ù‡ Ø¨ØµÙˆØ±Øª Ø²ÛŒÙ¾\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯ ---\n",
        "#@markdown ### Ù†Ø§Ù… Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯   :\n",
        "model_name = \"\" #@param {type:\"string\"}\n",
        "# -----------------------------\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not model_name.strip():\n",
        "    print(\"âŒ Ù„Ø·ÙØ§ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\")\n",
        "else:\n",
        "    # ØªØ¹Ø±ÛŒÙ Ù…Ø³ÛŒØ±Ù‡Ø§\n",
        "    model_dir = f'/content/Applio/logs/{model_name}'\n",
        "    drive_root = '/content/drive/MyDrive'\n",
        "    zip_path = f'{drive_root}/{model_name}_final_model.zip'\n",
        "\n",
        "    print(f\"Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡: {model_dir}\")\n",
        "\n",
        "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ 'best_epoch.pth'\n",
        "    latest_epoch = -1\n",
        "    latest_model_file = None\n",
        "\n",
        "    if not os.path.isdir(model_dir):\n",
        "        print(f\"âŒ Ø®Ø·Ø§: Ù¾ÙˆØ´Ù‡ Ù…Ø¯Ù„ '{model_dir}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")\n",
        "    else:\n",
        "        for filename in os.listdir(model_dir):\n",
        "            # ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ _best_epoch.pth ØªÙ…Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†\n",
        "            if filename.endswith(\"_best_epoch.pth\"):\n",
        "                match = re.search(r'_(\\d+)e_', filename)\n",
        "                if match:\n",
        "                    current_epoch = int(match.group(1))\n",
        "                    if current_epoch > latest_epoch:\n",
        "                        latest_epoch = current_epoch\n",
        "                        latest_model_file = filename\n",
        "\n",
        "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø§ÛŒÙ†Ø¯Ú©Ø³\n",
        "    index_file_name = f'{model_name}.index'\n",
        "    index_file_path = os.path.join(model_dir, index_file_name)\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾\n",
        "    if latest_model_file and os.path.exists(index_file_path):\n",
        "        latest_model_path = os.path.join(model_dir, latest_model_file)\n",
        "\n",
        "        print(f\"âœ… ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ: {latest_model_file}\")\n",
        "        print(f\"âœ… ÙØ§ÛŒÙ„ Ø§ÛŒÙ†Ø¯Ú©Ø³: {index_file_name}\")\n",
        "        print(f\"Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø¯Ø± Ù…Ø³ÛŒØ±: {zip_path}\")\n",
        "\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                zipf.write(latest_model_path, arcname=latest_model_file)\n",
        "                zipf.write(index_file_path, arcname=index_file_name)\n",
        "\n",
        "            print(f\"\\nâœ…âœ…âœ… ÙØ§ÛŒÙ„ '{os.path.basename(zip_path)}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ Ø´Ù…Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾: {e}\")\n",
        "\n",
        "    else:\n",
        "        if not latest_model_file:\n",
        "            print(\"âŒ Ø®Ø·Ø§: Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ÛŒ Ø¨Ø§ Ù¾Ø³ÙˆÙ†Ø¯ '_best_epoch.pth' Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ù…Ø¯Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")\n",
        "        if not os.path.exists(index_file_path):\n",
        "            print(f\"âŒ Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ø§ÛŒÙ†Ø¯Ú©Ø³ '{index_file_name}' Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ù…Ø¯Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cie6g8R17wQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <a href=\"https://colab.research.google.com/github/yaranbarzi/Applio/blob/main/Inference_2025.ipynb\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Inference%20RVC-Open%20in%20Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white\" alt=\"Inference RVC\"/>\n",
        "  </a>\n",
        "</p>\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <a href=\"https://youtube.com/@aigolden\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/YouTube-aigolden-FF0000?style=for-the-badge&logo=youtube&logoColor=white\" alt=\"YouTube Channel\"/>\n",
        "  </a>\n",
        "  &nbsp;&nbsp;\n",
        "  <a href=\"https://t.me/ai_golden\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Telegram-ai__golden-26A5E4?style=for-the-badge&logo=telegram&logoColor=white\" alt=\"Telegram Channel\"/>\n",
        "  </a>\n",
        "</p>"
      ],
      "metadata": {
        "id": "ZM-n4mJGBD4c"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ymMCTSD6m8qV"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}