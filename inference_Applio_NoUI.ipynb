{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Last Update\n",
        "12-11-2025"
      ],
      "metadata": {
        "id": "xOSZlwBISpBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CAXW55BQm0PP"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ’½ INSTALL RVC\n",
        "from multiprocessing import cpu_count\n",
        "cpu_cores = cpu_count()\n",
        "post_process = False\n",
        "LOGS_PATH = \"/content/Applio/logs\"\n",
        "BACKUPS_PATH = \"/content/drive/MyDrive/ApplioBackup\"\n",
        "\n",
        "%cd /content\n",
        "!git config --global advice.detachedHead false\n",
        "!git clone https://github.com/IAHispano/Applio --branch 3.5.1 --single-branch\n",
        "%cd /content/Applio\n",
        "\n",
        "# Install older python\n",
        "!apt update -y\n",
        "!apt install -y python3.11 python3.11-distutils python3.11-dev portaudio19-dev\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2\n",
        "!update-alternatives --set python3 /usr/bin/python3.11\n",
        "from sys import path\n",
        "path.append('/usr/local/lib/python3.11/dist-packages')\n",
        "\n",
        "print(\"Installing requirements...\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!uv pip install -q -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu128 --index-strategy unsafe-best-match\n",
        "!uv pip install -q jupyter-ui-poll\n",
        "!python core.py \"prerequisites\" --models \"True\" --pretraineds_hifigan \"True\"\n",
        "print(\"Finished installing requirements!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzaeMYsUE97Y"
      },
      "source": [
        "### **Infer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***Ø§Ø³Ù… Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø¨Ø®Ø´ Ù†Ø§Ù… Ù…Ø¯Ù„ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø­Ø§Ù„ØªÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³Øª***\n",
        "\n",
        "*   **ÛŒØ§ Ø§Ø³Ù… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù…Ø¯Ù„ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯ Ø²ÛŒÙ¾ Ø§Ø³Øª**\n",
        "\n",
        "*   **pth ÛŒØ§ Ø§Ø³Ù… ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ù…Ø¯Ù„ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯**\n",
        "\n",
        "*   **ÛŒØ§ Ù‡Ù…Ø§Ù† Ø§Ø³Ù…ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ØªØ¹ÛŒÛŒÙ† Ú©Ø±Ø¯ÛŒØ¯**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XwzHWayIT5-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Model (ZIP, TAR.GZ, or Drive Link)\n",
        "Model_Name = \"\" #@param {type:\"string\"}\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import tarfile  # Import tarfile for signature check\n",
        "\n",
        "if not Model_Name:\n",
        "    print(\"âŒ Error: Please enter the Model Name.\")\n",
        "else:\n",
        "    # Create model directory in target path\n",
        "    target_dir = f\"/content/Applio/logs/{Model_Name}\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    print(f\"Target directory created/exists: {target_dir}\")\n",
        "\n",
        "    # --- Download ---\n",
        "    downloaded_file_path = \"/content/downloaded_model\"\n",
        "    try:\n",
        "        if 'drive.google.com' in MODEL_LINK:\n",
        "            print(\"Downloading from Google Drive...\")\n",
        "            gdown.download(MODEL_LINK, downloaded_file_path, quiet=False, fuzzy=True)\n",
        "        elif MODEL_LINK.endswith(('.zip', '.tar.gz')):\n",
        "            print(f\"Downloading from direct link ({MODEL_LINK})...\")\n",
        "            os.system(f'wget -O {downloaded_file_path} \"{MODEL_LINK}\"')\n",
        "        else:\n",
        "            print(\"âŒ Error: Unsupported link type. Please provide a Google Drive link or a direct link to a .zip or .tar.gz file.\")\n",
        "            downloaded_file_path = None  # Indicate download failure\n",
        "\n",
        "        if downloaded_file_path and os.path.exists(downloaded_file_path):\n",
        "            print(\"âœ… Download successful.\")\n",
        "        elif downloaded_file_path:\n",
        "            print(\"âŒ Error: Download failed or file not found after download attempt.\")\n",
        "            downloaded_file_path = None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error during download: {e}\")\n",
        "        downloaded_file_path = None\n",
        "\n",
        "    # --- Extraction ---\n",
        "    if downloaded_file_path:\n",
        "        file_type = None\n",
        "        try:\n",
        "            # Try identifying as tar.gz first\n",
        "            with tarfile.open(downloaded_file_path, 'r:*') as tar:  # auto-detect compression\n",
        "                file_type = 'tar'\n",
        "                print(\"Detected file type: tar archive\")\n",
        "                temp_extract_dir = \"/content/temp_extract\"\n",
        "                os.makedirs(temp_extract_dir, exist_ok=True)\n",
        "                print(f\"Extracting {downloaded_file_path} to {temp_extract_dir}...\")\n",
        "                tar.extractall(path=temp_extract_dir)\n",
        "\n",
        "        except tarfile.ReadError:\n",
        "            # If not a tarfile, try as zip\n",
        "            try:\n",
        "                import zipfile\n",
        "                if zipfile.is_zipfile(downloaded_file_path):\n",
        "                    file_type = 'zip'\n",
        "                    print(\"Detected file type: zip archive\")\n",
        "                    print(f\"Extracting {downloaded_file_path} to {target_dir}...\")\n",
        "                    with zipfile.ZipFile(downloaded_file_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(target_dir)\n",
        "                else:\n",
        "                    print(\"âŒ Error: File is not a valid zip or tar archive.\")\n",
        "            except Exception as zip_e:\n",
        "                print(f\"âŒ Error processing as zip file: {zip_e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error during extraction detection/setup: {e}\")\n",
        "\n",
        "        # --- Copying/Moving files specifically for TAR archives ---\n",
        "        if file_type == 'tar':\n",
        "            files_copied = False\n",
        "            # Search and copy required files using os.walk\n",
        "            for root, dirs, files in os.walk(temp_extract_dir):\n",
        "                for file in files:\n",
        "                    if file.endswith('.pth'):\n",
        "                        source_path = os.path.join(root, file)\n",
        "                        dest_path = os.path.join(target_dir, file)\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                        print(f\"Copied PTH: {file} to {target_dir}\")\n",
        "                        files_copied = True\n",
        "\n",
        "                    if file.endswith('.index'):\n",
        "                        source_path = os.path.join(root, file)\n",
        "                        dest_path = os.path.join(target_dir, file)\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                        print(f\"Copied INDEX: {file} to {target_dir}\")\n",
        "                        files_copied = True\n",
        "\n",
        "            if not files_copied:\n",
        "                print(\"âš ï¸ Warning: No .pth or .index files found during deep search in extracted tar.\")\n",
        "\n",
        "            # Clean up temp extraction dir for tar\n",
        "            if os.path.exists(temp_extract_dir):\n",
        "                shutil.rmtree(temp_extract_dir)\n",
        "                print(f\"Removed temporary extraction directory: {temp_extract_dir}\")\n",
        "\n",
        "        # --- Cleanup Extraneous PTH Files (for BOTH zip and tar) ---\n",
        "        print(\"\\nğŸ§¹ Starting cleanup of extraneous PTH files...\")\n",
        "        expected_model_pth_filename = f\"{Model_Name}.pth\"\n",
        "        expected_model_pth_full_path = os.path.join(target_dir, expected_model_pth_filename)\n",
        "\n",
        "        # List all .pth files currently in the target directory\n",
        "        pth_files_in_target = glob.glob(os.path.join(target_dir, \"*.pth\"))\n",
        "        found_expected_pth = False\n",
        "\n",
        "        if not pth_files_in_target:\n",
        "            print(f\"âŒ Warning: No .pth files found in the final target directory {target_dir}.\")\n",
        "        else:\n",
        "            print(f\"Found PTH files: {[os.path.basename(f) for f in pth_files_in_target]}\")\n",
        "            # Check if the main expected file exists\n",
        "            if expected_model_pth_full_path in pth_files_in_target:\n",
        "                found_expected_pth = True\n",
        "                print(f\"âœ… Expected model file '{expected_model_pth_filename}' found.\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ Warning: Expected model file '{expected_model_pth_filename}' NOT found.\")\n",
        "\n",
        "            # Remove files starting with G_ or D_ OR any pth file if the expected one exists but this one isn't it\n",
        "            for pth_file_path in pth_files_in_target:\n",
        "                filename = os.path.basename(pth_file_path)\n",
        "                if filename.startswith(\"G_\") or filename.startswith(\"D_\"):\n",
        "                    try:\n",
        "                        os.remove(pth_file_path)\n",
        "                        print(f\"ğŸ§¹ Removed checkpoint file: {filename}\")\n",
        "                    except OSError as e:\n",
        "                        print(f\"âŒ Error removing file {filename}: {e}\")\n",
        "                elif found_expected_pth and pth_file_path != expected_model_pth_full_path:\n",
        "                    try:\n",
        "                        os.remove(pth_file_path)\n",
        "                        print(f\"ğŸ§¹ Removed other PTH file (since expected exists): {filename}\")\n",
        "                    except OSError as e:\n",
        "                        print(f\"âŒ Error removing file {filename}: {e}\")\n",
        "\n",
        "        # ğŸ” Ø§ÛŒÙ†Ø¬Ø§ Ù…Ù†Ø·Ù‚ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù†Ø§Ù… ØµØ­ÛŒØ­ Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        final_pth_files = glob.glob(os.path.join(target_dir, \"*.pth\"))\n",
        "        if final_pth_files:\n",
        "            # Ø§Ú¯Ø± Ù†Ø§Ù… ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø¹Ø« Ù†Ø´Ø¯Ù‡ ÙØ§ÛŒÙ„ {Model_Name}.pth Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆØ¯ØŒ\n",
        "            # ÙˆÙ„ÛŒ ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ pth Ø¯ÛŒÚ¯Ø± Ù‡Ø³ØªØŒ ÛŒÚ©ÛŒ Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡\n",
        "            if expected_model_pth_full_path not in final_pth_files:\n",
        "                # Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø­Ø§Ù„Øª: Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† pth Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù†Ø§Ù… ØµØ­ÛŒØ­ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\n",
        "                suggested_full = sorted(final_pth_files)[-1]\n",
        "                suggested_base = os.path.basename(suggested_full)\n",
        "                suggested_name = os.path.splitext(suggested_base)[0]\n",
        "\n",
        "                print(\"\\nâš ï¸ ØªÙˆØ¬Ù‡: Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ù†Ø§Ù…ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯ÛŒØ¯ Ø¨Ø§ Ù†Ø§Ù… ÙˆØ§Ù‚Ø¹ÛŒ ÙØ§ÛŒÙ„ pth ÛŒÚ©ÛŒ Ù†ÛŒØ³Øª.\")\n",
        "                print(f\"Ù†Ø§Ù… ØµØ­ÛŒØ­ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§ÛŒÙ† Ø§Ø³Øª:\")\n",
        "                print(f\"ğŸ‘‰  {suggested_name}\")\n",
        "                print(\"Ù„Ø·ÙØ§Ù‹ Ù‡Ù…ÛŒÙ† Ù†Ø§Ù… Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯ Ø¯Ø± ÙÛŒÙ„Ø¯ Ù†Ø§Ù… Ù…Ø¯Ù„ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ø³Ù„ÙˆÙ„ Ø§ÛŒÙ†ÙØ±ÙÙ†Ø³ Ø¯Ø±Ø³Øª Ú©Ø§Ø± Ú©Ù†Ø¯.\")\n",
        "\n",
        "        # Final listing to confirm\n",
        "        print(f\"\\nâœ… Extraction and cleanup complete for model '{Model_Name}'. Final contents:\")\n",
        "        os.system(f'ls -la \"{target_dir}\"')\n",
        "\n",
        "        # Clean up the downloaded archive file\n",
        "        os.remove(downloaded_file_path)\n",
        "        print(f\"Removed downloaded archive: {downloaded_file_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Skipping extraction due to download failure.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bBoxm_yGPvik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title ğŸ¶ Upload Target Audio\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"â³ Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù‡Ø± ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§ Ù†Ø§Ù… input.*\n",
        "    for f in glob.glob(\"/content/input.*\"):\n",
        "        os.remove(f)\n",
        "\n",
        "    original_filename = list(uploaded.keys())[0]\n",
        "    file_extension = os.path.splitext(original_filename)[1]\n",
        "    new_filename = f\"input{file_extension}\"\n",
        "    new_filepath = f\"/content/{new_filename}\"\n",
        "\n",
        "    shutil.copy2(original_filename, new_filepath)\n",
        "\n",
        "    print(f\"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± {new_filepath} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯\")\n",
        "    print(\"\\nğŸ“‚ ØªØ£ÛŒÛŒØ¯ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„:\")\n",
        "    !ls -l \"$new_filepath\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "Sbh4qf6CSfpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title ğŸ¶ Load Audio from Drive or Upload\n",
        "#@markdown Ø§ÛŒÙ† Ø³Ù„ÙˆÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ùˆ Ø§Ø² Ø¯Ø±Ø§ÛŒÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡\n",
        "\n",
        "AUDIO_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import mimetypes\n",
        "from IPython.display import Audio, display, clear_output\n",
        "import shutil\n",
        "\n",
        "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ File ID Ø§Ø² Ù„ÛŒÙ†Ú©\n",
        "file_id = AUDIO_LINK.split(\"/d/\")[1].split(\"/\")[0]\n",
        "print(\"ğŸ¯ File ID:\", file_id)\n",
        "\n",
        "# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ wget\n",
        "!wget -q --no-check-certificate \"https://docs.google.com/uc?export=download&id={file_id}\" -O temp_audio\n",
        "\n",
        "# ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ ÙØ§ÛŒÙ„\n",
        "mime_type, _ = mimetypes.guess_type(\"temp_audio\")\n",
        "\n",
        "if mime_type:\n",
        "    if \"wav\" in mime_type:\n",
        "        original_extension = \".wav\"\n",
        "    elif \"mpeg\" in mime_type or \"mp3\" in mime_type:\n",
        "        original_extension = \".mp3\"\n",
        "    elif \"ogg\" in mime_type:\n",
        "        original_extension = \".ogg\"\n",
        "    elif \"flac\" in mime_type:\n",
        "        original_extension = \".flac\"\n",
        "    else:\n",
        "        original_extension = \".wav\"  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "else:\n",
        "    original_extension = \".wav\"\n",
        "\n",
        "# ØªØºÛŒÛŒØ± Ù†Ø§Ù…\n",
        "new_filename = f\"input{original_extension}\"\n",
        "new_filepath = f\"/content/{new_filename}\"\n",
        "shutil.move(\"temp_audio\", new_filepath)\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ùˆ Ù¾Ø®Ø´\n",
        "clear_output(wait=True)\n",
        "display(Audio(new_filepath))\n",
        "print(f\"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {new_filepath}\")\n",
        "!ls -lh \"$new_filepath\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "JTXIFFvwSjpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lrCKEOzvDPRu"
      },
      "outputs": [],
      "source": [
        "# @title Run Inference\n",
        "# @markdown ####  `Ø§Ø³Ù… Ù…Ø¯Ù„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†`\n",
        "%cd /content/Applio\n",
        "from pathlib import Path\n",
        "\n",
        "model_name = \"\"  # @param {type:\"string\"}\n",
        "model_path = Path(f\"{LOGS_PATH}/{model_name}\")\n",
        "if not (model_path.exists() and model_path.is_dir()):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_path.resolve()}\")\n",
        "\n",
        "# Select either the last checkpoint or the final weight\n",
        "!ls -t \"{model_path}\"/\"{model_name}\"_*e_*s.pth \"{model_path}\"/\"{model_name}\".pth 2> /dev/null | head -n 1 > /tmp/pth.txt\n",
        "pth_file = open(\"/tmp/pth.txt\", \"r\").read().strip()\n",
        "if pth_file == \"\":\n",
        "  raise FileNotFoundError(f\"No model weight found in directory: {model_path.resolve()}\\nMake sure that the file is properly named (e.g. \\\"{model_name}.pth)\\\"\")\n",
        "\n",
        "!ls -t \"{model_path}\"/*.index | head -n 1 > /tmp/index.txt\n",
        "index_file = open(\"/tmp/index.txt\", \"r\").read().strip()\n",
        "\n",
        "input_path = \"/content/input.wav\"\n",
        "output_path = \"/content/output.wav\"\n",
        "export_format = \"WAV\"  # @param ['WAV', 'MP3', 'FLAC', 'OGG', 'M4A'] {allow-input: false}\n",
        "f0_method = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\", \"hybrid[rmvpe+fcpe]\"] {allow-input: false}\n",
        "# @markdown ####  `ØªÙ†Ø¸ÛŒÙ… Ù¾ÛŒÚ† ØµØ¯Ø§`\n",
        "f0_up_key = 0  # @param {type:\"slider\", min:-24, max:24, step:0}\n",
        "rms_mix_rate = 0.8  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "protect = 0.5  # @param {type:\"slider\", min:0.0, max:0.5, step:0.1}\n",
        "index_rate = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "clean_strength = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "split_audio = False  # @param{type:\"boolean\"}\n",
        "clean_audio = False  # @param{type:\"boolean\"}\n",
        "f0_autotune = False  # @param{type:\"boolean\"}\n",
        "formant_shift = False # @param{type:\"boolean\"}\n",
        "formant_qfrency = 1.0 # @param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "formant_timbre = 1.0 # @param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "embedder_model = \"contentvec\" # @param [\"contentvec\", \"chinese-hubert-base\", \"japanese-hubert-base\", \"korean-hubert-base\", \"custom\"] {allow-input: false}\n",
        "embedder_model_custom = \"\" # @param {type:\"string\"}\n",
        "\n",
        "!rm -f \"{output_path}\"\n",
        "if post_process:\n",
        "  !python core.py infer --pitch \"{f0_up_key}\" --volume_envelope \"{rms_mix_rate}\" --index_rate \"{index_rate}\" --protect \"{protect}\" --f0_autotune \"{f0_autotune}\" --f0_method \"{f0_method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"{export_format}\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\" --formant_shifting \"{formant_shift}\" --formant_qfrency \"{formant_qfrency}\" --formant_timbre \"{formant_timbre}\" --post_process \"{post_process}\" --reverb \"{reverb}\" --pitch_shift \"{pitch_shift}\" --limiter \"{limiter}\" --gain \"{gain}\" --distortion \"{distortion}\" --chorus \"{chorus}\" --bitcrush \"{bitcrush}\" --clipping \"{clipping}\" --compressor \"{compressor}\" --delay \"{delay}\" --reverb_room_size \"{reverb_room_size}\" --reverb_damping \"{reverb_damping}\" --reverb_wet_gain \"{reverb_wet_gain}\" --reverb_dry_gain \"{reverb_dry_gain}\" --reverb_width \"{reverb_width}\" --reverb_freeze_mode \"{reverb_freeze_mode}\" --pitch_shift_semitones \"{pitch_shift_semitones}\" --limiter_threshold \"{limiter_threshold}\" --limiter_release_time \"{limiter_release_time}\" --gain_db \"{gain_db}\" --distortion_gain \"{distortion_gain}\" --chorus_rate \"{chorus_rate}\" --chorus_depth \"{chorus_depth}\" --chorus_center_delay \"{chorus_center_delay}\" --chorus_feedback \"{chorus_feedback}\" --chorus_mix \"{chorus_mix}\" --bitcrush_bit_depth \"{bitcrush_bit_depth}\" --clipping_threshold \"{clipping_threshold}\" --compressor_threshold \"{compressor_threshold}\" --compressor_ratio \"{compressor_ratio}\" --compressor_attack \"{compressor_attack}\" --compressor_release \"{compressor_release}\" --delay_seconds \"{delay_seconds}\" --delay_feedback \"{delay_feedback}\" --delay_mix \"{delay_mix}\"\n",
        "else:\n",
        "  !python core.py infer --pitch \"{f0_up_key}\" --volume_envelope \"{rms_mix_rate}\" --index_rate \"{index_rate}\" --protect \"{protect}\" --f0_autotune \"{f0_autotune}\" --f0_method \"{f0_method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"{export_format}\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\" --formant_shifting \"{formant_shift}\" --formant_qfrency \"{formant_qfrency}\" --formant_timbre \"{formant_timbre}\" --post_process \"{post_process}\"\n",
        "\n",
        "if Path(output_path).exists():\n",
        "  from IPython.display import Audio, display\n",
        "  output_path = output_path.replace(\".wav\", f\".{export_format.lower()}\")\n",
        "  display(Audio(output_path, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title â¬‡ï¸ Download Final Output\n",
        "from google.colab import files\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import Audio, display, clear_output\n",
        "\n",
        "\n",
        "output_files = glob.glob(\"/content/output.*\")\n",
        "if not output_files:\n",
        "    print(\"Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!\")\n",
        "else:\n",
        "    # Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† Ø³Ø§Ø®Øª\n",
        "    latest_file = max(output_files, key=os.path.getmtime)\n",
        "    filename = os.path.basename(latest_file)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f\"Ø¢Ø®Ø±ÛŒÙ† Ø®Ø±ÙˆØ¬ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:\")\n",
        "    print(f\"ğŸµ {filename}\")\n",
        "    print(f\"ğŸ“ Ø­Ø¬Ù…: {os.path.getsize(latest_file)/1024/1024:.2f} MB\")\n",
        "    print(f\"â° Ø²Ù…Ø§Ù† Ø³Ø§Ø®Øª: {os.path.getmtime(latest_file):.0f}\")\n",
        "\n",
        "    # Ù¾Ø®Ø´ ØµØ¯Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯\n",
        "    display(Audio(latest_file, autoplay=False))\n",
        "\n",
        "    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø±\n",
        "    files.download(latest_file)\n",
        "\n",
        "    print(\"\\nØ¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø±ÙˆØ¹ Ø´Ø¯...\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D0em8MuI9iYV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}